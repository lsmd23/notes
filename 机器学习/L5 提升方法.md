# 集成学习
- 定义：训练多个学习器，用多个学习器的组合来完成学习任务的方法
- 分类：
	- 并行集成（Parallel Ensemble）：多个学习器相互独立地训练，最后将它们的结果进行组合，如[[L5 学习(B)#随机森林|随机森林]]
		- 训练高效，但互补性一般
	- 串行集成（Sequential Ensemble）：多个学习器依次训练，后续的学习器依赖于前面的学习器的结果，如提升方法（Boosting）
		- 训练较慢，但互补性较强
- 理论基础：


# 提升方法（Boosting）
- 弱学习器（Weak Learner）：分类误差率略低于随机猜测的学习器
	- 定义：对二分类学习器，若存在二分类学习算法$\mathcal A$，$\gamma > 0$，使得对于任意分布$D$，
	- 例：
		- 决策树桩（Decision Stump）：仅使用单个特征进行划分的决策树
		- 回归桩（Regression Stump）：仅使用单个特征进行划分的回归树
- 提升方法（Boosting）：
	- 思想：通过训练多个弱学习器，并将它们的结果进行组合，得到一个强学习器
		- 示意：![[Pasted image 20251124154505.png]]


# 自适应提升（AdaBoost）


# 梯度提升（Gradient Boosting）
