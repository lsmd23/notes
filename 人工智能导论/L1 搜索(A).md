- 反射型智能体：给定一个输入的信号x，给出单一的反应y;
- 规划型智能体：对给定的一个输入的信号x，给出一系列的反应$a_1,a_2,...$
# 搜索类问题
## 问题组成
- 状态空间$S$：包含问题的各个状态
- 初始状态$s_0$：问题的初始状态
- 动作集合$A(s)$：对象所能完成的各种动作
- 状态转移模型$Result(s,a)$：一种后继函数，描述动作之后状态的更新
- 目标状态$G(s)$
- 动作代价$c(s,a,s')$：由某个动作从一个状态到另一个状态的花费
- 例：![[Pasted image 20250224153439.png]]
## 搜索模型
- 由实际问题定义出的搜索问题所形成的搜索模型
- 因抽象会导致模型和实际世界有所区别，称为虚拟现实鸿沟(Reality gap)
- 在模型中，可以进行不断地搜索，称为模拟(Simulation)
# 全局搜索
## 基本概念
- 状态空间图：对搜索问题的模型构建的一个图，节点对应状态，每个状态转移对应一条边，搜索问题即为找到一条从初始态到目标态的路径
- 搜索树：对状态图进行搜索形成的一棵树，每个结点对应唯一的从根节点的一条路径
- 搜索树对应状态空间图的一种算法
- ![[Pasted image 20250224154605.png]]
## 全局树搜索
- 算法：![[Pasted image 20250224154823.png]]
- 问题：
	- 搜索出的路径不一定是最优的![[Pasted image 20250224155049.png]]
	- 根据状态图，可能产生大量的冗余搜索![[Pasted image 20250224155054.png]]
## 全局图搜索
- 算法改进：加入一个探索集，以防止重复的搜索![[Pasted image 20250224155159.png]]
- 问题：可能需要储存一个探索集，有额外的空间开销
- 边缘集：在图搜索过程中，存在一个边缘集，是搜索算法中等待检查的状态。对任何一个结点，在未被探索和已被探索中，存在有这样的边缘集状态的临界点
# 无信息搜索
## 深度优先搜索(DFS)
- 深度优先，一直寻找直至没有可行的状态转移
- 边缘集是先进后出的栈，即形成深度优先搜索
- DFS的性质：
	- 基本概念：对搜索树，有分支因子b，最大深度m
	- 完备性：m若有限，则完备；若图中有环，则搜索树的m成为无限的，不完备
	- 最优性：并非能找到最优解
	- 时间复杂度：$O(b^m)$
	- 空间复杂度：$O(bm)$，相对省空间
## 广度优先搜索(BFS)
- 广度优先，先检查整整一层，再深入
- 边缘集是先进先出的队列，即形成广度优先搜索
- BFS的性质：
	- 完备性：是完备的
	- 最优性：能找到最优解
	- 时间复杂度：$O(b^d)$
	- 空间复杂度：$O(b^d)$
## 迭代深化搜索(IDS)
- 将两种搜索结合起来，设定一个最大搜索深度，对每个深度的值，进行一次深度优先搜索，未找到解，递增搜索深度
- IDS的性质：
	- 时间复杂度：$O(b^d)$
	- 空间复杂度：$O(bd)$
	- 完备的，且是最优的
## 一致代价搜索(UCS)
- 实际问题中，搜索的每条路径权重不同
- 边缘集是一个优先队列，其路径代价小的置于优先队列的前端，大的则对应在后端
- **代价函数$g(n)$**：从根节点到目标结点的代价和
- UCS的性质：
	- 时间复杂度：若结果的代价和为$C^*$，每个边的平均代价为$\epsilon$，则复杂度为$O(b^{C^*/\epsilon})$
	- 空间复杂度：$O(b^{C^*/\epsilon})$
	- 完备的，且是最优的
## 总结
![[Pasted image 20250224162056.png]]
# 启发式搜索
在搜索时，引入一些宏观的信息，用于指示一个搜索的大方向，即为启发式的搜索
## 贪心搜索
- **启发函数$h(n)$**：从状态n到目标状态的距离
- 根据这个启发函数进行的搜索，即为贪心搜索
- 问题：启发函数是未知的，因而很容易产生无法找到解的情况，即使找到解，也不一定最优
- 性质：
	- 不完备，也不最优
	- 相对速度很快，时间代价很小
## A\*搜索
- 将UCS和贪心搜索结合起来，同时考虑代价函数和启发函数：$f(n)=g(n)+h(n)$
- **可采纳条件**：在估计代价时，要求估计值一定不能高于实际值$0\leq h(n)\leq h^*(n)$
	- 满足可采纳条件时，这样的搜索可以找到最优解
- A\*搜索的效率：h(n)越大，其对搜索的限制就越大，其效率就越高
	- ![[Pasted image 20250224164918.png]]
- **启发函数的求解**：
	- 松弛求解：将问题的约束条件减少，使得问题的解集扩大，从而求解出一套启发函数的值
	- 松弛的解集越大，启发函数的值越小
	- 对不同的启发函数，可能在某些状态，$h_1(n)$更好，在另一些状态$h_2(n)$更好，这时可以取$h(n)=max\{h_i(n)\}$
- **加权的A\*搜索**：$f(n)=g(n)+W\cdot h(n)$
