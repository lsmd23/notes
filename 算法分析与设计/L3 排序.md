# 快速排序
- 思想：分治法
	- 划分：按枢轴元pivot划分为大小两个数组
	- 解决：递归解决
	- 合并：显然
- 伪码实现：
	- 对$[p,r]$区间以$A[r]$为枢轴进行分区![[Pasted image 20250311080733.png]]
- 复杂度分析：
	- 最坏情况下：每次分区一侧只有一个元素$$T(n)=T(0)+T(n-1)+\Theta(n)=\Theta(n^2)$$
	- 最好情况下：每次都均匀地分成两部分$$T(n)=2T(n/2)+\Theta(n)=\Theta(n\lg n)$$即使不是最好情况，通过递归树推导，依然可以得到复合渐进紧界的表达式$$c_1n\lg n\leq T(n)\leq c_2n\lg n$$
	- 交替出现时，例如：$$L(n)=2U(n/2)+\Theta(n),U(n)=L(n-1)+\Theta(n),$$依然可以分析得到其复杂度：$$L(n) = 2(L(n/2 − 1) + \Theta(n/2)) + \Theta(n)= 2L(n/2 − 1) + \Theta(n)= \Theta(n \lg n)$$
- 随机化快速排序：
	- 实现：取随机的元素作为分区的枢轴![[Pasted image 20250311083124.png]]
	- 期望值分析——归纳法证明：
		- 对每次分区，只有一个使之达到最坏的分区情况，每个元素被最坏分割的期望值$X_k=\frac{1}{n}$
		- 对递归式的所有情况求和：![[Pasted image 20250311083922.png]]
		- 利用期望的性质，进行化简：![[Pasted image 20250311084242.png]]![[Pasted image 20250311084323.png]]
		- 采用归纳法证明上下界即可，举上界为例，由归纳假设，只需证：$$E[T(n)]\leq \frac{2}{n}\sum_{k=2}^{n-1}ak\lg k+\Theta(n)$$由数学推导可得：$$\sum_{k=2}^{n-1}k\lg k\leq \frac{1}{2}n^2\lg n-\frac{1}{8}n^2$$进而可以得到：$$E[T(n)]\leq an\lg n-(\frac{an}{4}-\Theta(n))\leq an\lg n$$
	- 期望值分析——随机变量分析：
		- 直接从算法本身开始分析，每次比较的次数是随机变量，记为$X$，则每次子问题的解决需要$O(n+X)$
		- 定义指标随机变量$X_{ij}$表示$i,j$两元素是否被比较，则：$$X=\sum_{i=1}^{n-1}\sum_{j=i+1}^{n}X_{ij}$$
		- 求期望：$$E[X]=\sum_{i=1}^{n-1}\sum_{j=i+1}^{n}E[X_{ij}]=\sum_{i=1}^{n-1}\sum_{j=i+1}^{n}P(z_i元素和z_j元素发生比较)$$
		- 由概率分析，当且仅当$z_i$和$z_j$中间的元素被选为枢轴时，二者不会发生比较，故$P(z_i元素和z_j元素发生比较)=\frac{2}{j-i+1}$
		- 进而：$$E[X]<\sum_{i=1}^{n-1}\sum_{j=i+1}^{n}\frac{2}{k}=\sum_{i=1}^{n-1}O(\lg n)=O(n\lg n)$$
- 快速排序的优势：每次访问的是连续的内存，对大规模的数据，可以有效减少不连续内存的访问，进而**高效地利用缓存机制，减少不同层次内存之间的I/O次数**
# 线性复杂度排序算法
## 比较排序的下界
- 建立决策树模型，每次比较顺序的决策都决定了一部分的顺序，树的叶子节点表示排序的结果
- 排序方式要是完备的，则树的叶子节点必须包含一个序列的全部排列情况；同时，对一棵决策树，树的深度即为完成叶子节点的排序的用时；相同排列对应的叶子节点，最深的即为用时的上界，最浅的即为下界
- 因此，树的叶子节点数至少有$n!$个，树的高度为$h$，则树的叶子节点数至多为$2^h$，则$n!\leq 2^h$，因此：$h\geq \lg(n!)=\Omega(n\lg n)$
## 基数排序
- 思想：利用一个辅助空间实现排序
- 实现：
	- 伪代码：![[Pasted image 20250311094117.png]]
		- 第一遍，$C[i]$的每个位置上是$A[i]$中等于$i$的元素的数目
		- 第二遍，$C[i]$的每个位置上是$A[i]$中小于等于$i$的元素的数目
		- 最后按照映射关系，将原数组的数映射到新数组即可
	- 分析：
		- 时间复杂度：$O(n+k)$
		- 空间复杂度：$O(k)$
		- 缺点：$k$的范围应当包含原数组中数据的范围，当这个范围很大时，排序需要极大的空间，效率低下
































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































